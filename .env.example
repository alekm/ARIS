# ARIS Environment Configuration
# Copy this file to .env and update with your settings

# ============================================
# API Configuration
# ============================================
API_PORT=8000
API_HOST=0.0.0.0

# ============================================
# Redis Configuration
# ============================================
REDIS_HOST=redis
REDIS_PORT=6379

# ============================================
# Audio Capture Configuration
# ============================================
# NOTE: KiwiSDR slots are now configured via the Web UI or API endpoints.
# Environment variables below are only for backward compatibility auto-start.
# To configure slots, use the Web UI at http://localhost:8000 or the API:
#   POST /api/slots/{slot_id}/start with slot configuration

# Auto-start slot 0 from environment (optional, for backward compatibility)
# Set MODE=kiwi and KIWI_HOST to enable auto-start of slot 0
MODE=kiwi
KIWI_HOST=
KIWI_PORT=8073
KIWI_PASSWORD=
FREQUENCY_HZ=7200000
DEMOD_MODE=USB

# ============================================
# STT (Speech-to-Text) Configuration
# ============================================
# Model size: tiny, base, small, medium, large-v2, large-v3
MODEL_SIZE=medium

# Device: cuda or cpu
DEVICE=cuda

# Voice activity detection threshold (0.0-1.0)
VAD_THRESHOLD=0.5

# Energy threshold for speech detection (0.0-1.0)
ENERGY_THRESHOLD=0.01

# ============================================
# LLM (Summarization) Configuration
# ============================================
# Backend: ollama, openai, or llama-cpp
LLM_BACKEND=ollama

# Model name (varies by backend)
LLM_MODEL=llama3.2:latest

# LLM server host (for ollama: host.docker.internal:11434)
LLM_HOST=host.docker.internal:11434

# API key (if required by backend)
LLM_API_KEY=

# ============================================
# Database Configuration
# ============================================
DATABASE_URL=sqlite:////data/db/aris.db

# ============================================
# Logging Configuration
# ============================================
# Log level for all services: DEBUG, INFO, WARNING, ERROR, CRITICAL
# Log level for all services: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=WARNING

# ============================================
# HF_TOKEN
# ============================================
# Use for higher limits on huggingface
HF_TOKEN=
